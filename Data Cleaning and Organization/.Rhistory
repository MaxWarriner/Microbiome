return(model)
}
# Initialize variables to remove
vars_to_remove <- character()
# 1. Handle numeric predictors -----------------------------------------------
numeric_cols <- sapply(predictors, is.numeric)
numeric_vars <- names(predictors)[numeric_cols]
if (length(numeric_vars) >= 2) {
# Calculate correlation matrix for numeric predictors
numeric_predictors <- predictors[, numeric_vars, drop = FALSE]
cor_matrix <- cor(numeric_predictors, use = "complete.obs")
# Find highly correlated pairs
highly_correlated <- which(abs(cor_matrix) > threshold & upper.tri(cor_matrix), arr.ind = TRUE)
if (nrow(highly_correlated) > 0) {
# Get correlated pairs
correlated_pairs <- data.frame(
Var1 = numeric_vars[highly_correlated[, 1]],
Var2 = numeric_vars[highly_correlated[, 2]],
Correlation = cor_matrix[highly_correlated]
)
message("Highly correlated numeric predictor pairs (threshold = ", threshold, "):")
print(correlated_pairs)
# Identify variables to remove (keeping one from each pair)
for (i in 1:nrow(correlated_pairs)) {
pair <- as.character(correlated_pairs[i, 1:2])
if (!(pair[1] %in% vars_to_remove) && !(pair[2] %in% vars_to_remove)) {
vars_to_remove <- c(vars_to_remove, pair[2])
}
}
} else {
message("No numeric predictors are highly correlated (above threshold = ", threshold, ")")
}
} else if (length(numeric_vars) > 0) {
message("Only ", length(numeric_vars), " numeric predictor - cannot calculate correlations")
}
# 2. Handle categorical predictors -------------------------------------------
categorical_vars <- names(predictors)[!numeric_cols & sapply(predictors, function(x) is.factor(x) | is.character(x))]
if (length(categorical_vars) > 0) {
message("\nChecking categorical predictors for outcome correlation...")
# Get the response variable
y <- model_data[[response_name]]
for (cat_var in categorical_vars) {
x <- predictors[[cat_var]]
# Calculate mean outcome by category (for numeric response)
if (is.numeric(y)) {
means <- tapply(y, x, mean, na.rm = TRUE)
if (length(means) > 1) {
# Calculate pairwise absolute differences in means
mean_diff <- as.matrix(dist(means))
# Normalize by overall range of y
normalized_diff <- mean_diff / diff(range(y, na.rm = TRUE))
# Find categories with very similar means
similar_cats <- which(normalized_diff < (1 - cat_threshold) & upper.tri(normalized_diff), arr.ind = TRUE)
if (nrow(similar_cats) > 0) {
message("Categorical variable '", cat_var, "' has categories with similar outcome means:")
pairs <- data.frame(
Cat1 = levels(x)[similar_cats[, 1]],
Cat2 = levels(x)[similar_cats[, 2]],
MeanDiff = mean_diff[similar_cats],
NormalizedDiff = normalized_diff[similar_cats]
)
print(pairs)
# Consider removing this categorical variable if many similar categories
if (mean(normalized_diff) < (1 - cat_threshold)) {
message("> Considering removing '", cat_var, "' (many similar categories)")
vars_to_remove <- c(vars_to_remove, cat_var)
}
}
}
}
# For binary response, check proportion differences
if (is.factor(y) && nlevels(y) == 2) {
prop_table <- prop.table(table(x, y), 1)
if (any(apply(prop_table, 1, function(p) max(p) > cat_threshold))) {
message("Categorical variable '", cat_var, "' has categories with similar outcome proportions")
print(prop_table)
# Consider removing if any category predicts outcome too well
vars_to_remove <- c(vars_to_remove, cat_var)
}
}
}
}
# 3. Process removals -------------------------------------------------------
if (length(vars_to_remove) == 0) {
message("\nNo variables need to be removed based on correlation thresholds")
return(model)
}
message("\nRemoving these variables to reduce multicollinearity/similarity:")
message(paste(vars_to_remove, collapse = ", "))
# Create new formula without the problematic variables
remaining_vars <- setdiff(names(predictors), vars_to_remove)
new_formula <- reformulate(remaining_vars, response = response_name)
# Refit the model
new_model <- update(model, formula. = new_formula)
return(new_model)
}
model <- remove_highly_correlated(model) # remove colinear variables from data
#Perform Multivariable Linear Regression
summary(model)
#perform stepwise regression
library(MASS)
model = stepAIC(model, direction = "both", trace = FALSE) # Stepwise regression model with shannon measure
summary(model)
ps <- readRDS("continuous_data.rds") # read in ps file
#Rarefy Data
set.seed(13)
ps <- rarefy_even_depth(ps, 1e+05)
a_diversity <- estimate_richness(ps, measures = c("Shannon", "Chao1")) # calculate alpha diversity of each sample
sample_data <- ps@sam_data #extract sample data
sample_data$sample <- rownames(sample_data) #create column with sample
a_diversity$sample <- rownames(sample_data) #create same column in diversity object to be able to merge by
sample_data <- data.frame(sample_data) #convert sample data to data frame for merging
a_diversity <- merge(sample_data, a_diversity, by = c("sample")) #merge the data together
a_diversity <- a_diversity |> # remove unnecessary columns for the model
dplyr::select(-sample, -se.chao1)
a_diversity <- mutate_if(a_diversity, is.character, as.factor) #change all character columns to factor
a_diversity <- a_diversity %>%
dplyr::select_if(~ !(is.factor(.) & nlevels(.) == 1)) # remove all columns where factor only has one level
a_diversity <- a_diversity |>
mutate(Chao_plus = Chao1/mean(a_diversity$Chao1)*100,
Shannon_plus = Shannon/mean(a_diversity$Shannon)*100,
Chao_Shannon = (Chao_plus + Shannon_plus)/2)
a_diversity <- a_diversity %>%
dplyr::select_if(~ length(unique(.)) > 1) # remove all columns where numeric has only one level
remove_na_columns <- function(df) {
# Check which columns have any NA values
na_columns <- sapply(df, function(x) any(is.na(x)))
# Keep only columns without NAs
df_clean <- df[, !na_columns, drop = FALSE]
return(df_clean)
}
a_diversity <- remove_na_columns(a_diversity)
a_diversity <- a_diversity |>
dplyr::select(-Chao1, -Chao_plus, -Shannon, -Shannon_plus)
a_diversity <- a_diversity[,c(1:16, 33:46, 54:78, 88:93, 116)]
model <- lm(Chao_Shannon ~ ., data = a_diversity, na.action = na.omit)
summary(model)
remove_highly_correlated <- function(model, threshold = 0.7, cat_threshold = 0.9) {
# Check if the input is a linear regression model
if (!inherits(model, "lm")) {
stop("Input must be a linear regression model (lm object)")
}
# Get the model data
model_data <- model.frame(model)
response_name <- names(model_data)[1]
predictors <- model_data[-1]  # Remove response variable
# Check if there are at least 2 predictors
if (ncol(predictors) < 2) {
message("Model has fewer than 2 predictors - nothing to check")
return(model)
}
# Initialize variables to remove
vars_to_remove <- character()
# 1. Handle numeric predictors -----------------------------------------------
numeric_cols <- sapply(predictors, is.numeric)
numeric_vars <- names(predictors)[numeric_cols]
if (length(numeric_vars) >= 2) {
# Calculate correlation matrix for numeric predictors
numeric_predictors <- predictors[, numeric_vars, drop = FALSE]
cor_matrix <- cor(numeric_predictors, use = "complete.obs")
# Find highly correlated pairs
highly_correlated <- which(abs(cor_matrix) > threshold & upper.tri(cor_matrix), arr.ind = TRUE)
if (nrow(highly_correlated) > 0) {
# Get correlated pairs
correlated_pairs <- data.frame(
Var1 = numeric_vars[highly_correlated[, 1]],
Var2 = numeric_vars[highly_correlated[, 2]],
Correlation = cor_matrix[highly_correlated]
)
message("Highly correlated numeric predictor pairs (threshold = ", threshold, "):")
print(correlated_pairs)
# Identify variables to remove (keeping one from each pair)
for (i in 1:nrow(correlated_pairs)) {
pair <- as.character(correlated_pairs[i, 1:2])
if (!(pair[1] %in% vars_to_remove) && !(pair[2] %in% vars_to_remove)) {
vars_to_remove <- c(vars_to_remove, pair[2])
}
}
} else {
message("No numeric predictors are highly correlated (above threshold = ", threshold, ")")
}
} else if (length(numeric_vars) > 0) {
message("Only ", length(numeric_vars), " numeric predictor - cannot calculate correlations")
}
# 2. Handle categorical predictors -------------------------------------------
categorical_vars <- names(predictors)[!numeric_cols & sapply(predictors, function(x) is.factor(x) | is.character(x))]
if (length(categorical_vars) > 0) {
message("\nChecking categorical predictors for outcome correlation...")
# Get the response variable
y <- model_data[[response_name]]
for (cat_var in categorical_vars) {
x <- predictors[[cat_var]]
# Calculate mean outcome by category (for numeric response)
if (is.numeric(y)) {
means <- tapply(y, x, mean, na.rm = TRUE)
if (length(means) > 1) {
# Calculate pairwise absolute differences in means
mean_diff <- as.matrix(dist(means))
# Normalize by overall range of y
normalized_diff <- mean_diff / diff(range(y, na.rm = TRUE))
# Find categories with very similar means
similar_cats <- which(normalized_diff < (1 - cat_threshold) & upper.tri(normalized_diff), arr.ind = TRUE)
if (nrow(similar_cats) > 0) {
message("Categorical variable '", cat_var, "' has categories with similar outcome means:")
pairs <- data.frame(
Cat1 = levels(x)[similar_cats[, 1]],
Cat2 = levels(x)[similar_cats[, 2]],
MeanDiff = mean_diff[similar_cats],
NormalizedDiff = normalized_diff[similar_cats]
)
print(pairs)
# Consider removing this categorical variable if many similar categories
if (mean(normalized_diff) < (1 - cat_threshold)) {
message("> Considering removing '", cat_var, "' (many similar categories)")
vars_to_remove <- c(vars_to_remove, cat_var)
}
}
}
}
# For binary response, check proportion differences
if (is.factor(y) && nlevels(y) == 2) {
prop_table <- prop.table(table(x, y), 1)
if (any(apply(prop_table, 1, function(p) max(p) > cat_threshold))) {
message("Categorical variable '", cat_var, "' has categories with similar outcome proportions")
print(prop_table)
# Consider removing if any category predicts outcome too well
vars_to_remove <- c(vars_to_remove, cat_var)
}
}
}
}
# 3. Process removals -------------------------------------------------------
if (length(vars_to_remove) == 0) {
message("\nNo variables need to be removed based on correlation thresholds")
return(model)
}
message("\nRemoving these variables to reduce multicollinearity/similarity:")
message(paste(vars_to_remove, collapse = ", "))
# Create new formula without the problematic variables
remaining_vars <- setdiff(names(predictors), vars_to_remove)
new_formula <- reformulate(remaining_vars, response = response_name)
# Refit the model
new_model <- update(model, formula. = new_formula)
return(new_model)
}
model <- remove_highly_correlated(model) # remove colinear variables from data
#Perform Multivariable Linear Regression
summary(model)
ps <- readRDS("continuous_data.rds") # read in ps file
#Rarefy Data
set.seed(13)
ps <- rarefy_even_depth(ps, 1e+05)
a_diversity <- estimate_richness(ps, measures = c("Shannon", "Chao1")) # calculate alpha diversity of each sample
sample_data <- ps@sam_data #extract sample data
sample_data$sample <- rownames(sample_data) #create column with sample
a_diversity$sample <- rownames(sample_data) #create same column in diversity object to be able to merge by
sample_data <- data.frame(sample_data) #convert sample data to data frame for merging
a_diversity <- merge(sample_data, a_diversity, by = c("sample")) #merge the data together
a_diversity <- a_diversity |> # remove unnecessary columns for the model
dplyr::select(-sample, -se.chao1)
a_diversity <- mutate_if(a_diversity, is.character, as.factor) #change all character columns to factor
a_diversity <- a_diversity %>%
dplyr::select_if(~ !(is.factor(.) & nlevels(.) == 1)) # remove all columns where factor only has one level
a_diversity <- a_diversity |>
mutate(Chao_plus = Chao1/mean(a_diversity$Chao1)*100,
Shannon_plus = Shannon/mean(a_diversity$Shannon)*100,
Chao_Shannon = (Chao_plus + Shannon_plus)/2)
a_diversity <- a_diversity %>%
dplyr::select_if(~ length(unique(.)) > 1) # remove all columns where numeric has only one level
remove_na_columns <- function(df) {
# Check which columns have any NA values
na_columns <- sapply(df, function(x) any(is.na(x)))
# Keep only columns without NAs
df_clean <- df[, !na_columns, drop = FALSE]
return(df_clean)
}
a_diversity <- remove_na_columns(a_diversity)
a_diversity <- a_diversity |>
dplyr::select(-Chao1, -Chao_plus, -Shannon, -Shannon_plus)
a_diversity <- a_diversity[,c(1:16, 33:46, 54:78, 88:93, 116)]
model <- lm(Chao_Shannon ~ ., data = a_diversity, na.action = na.omit)
summary(model)
remove_highly_correlated <- function(model, threshold = 0.9, cat_threshold = 0.95) {
# Check if the input is a linear regression model
if (!inherits(model, "lm")) {
stop("Input must be a linear regression model (lm object)")
}
# Get the model data
model_data <- model.frame(model)
response_name <- names(model_data)[1]
predictors <- model_data[-1]  # Remove response variable
# Check if there are at least 2 predictors
if (ncol(predictors) < 2) {
message("Model has fewer than 2 predictors - nothing to check")
return(model)
}
# Initialize variables to remove
vars_to_remove <- character()
# 1. Handle numeric predictors -----------------------------------------------
numeric_cols <- sapply(predictors, is.numeric)
numeric_vars <- names(predictors)[numeric_cols]
if (length(numeric_vars) >= 2) {
# Calculate correlation matrix for numeric predictors
numeric_predictors <- predictors[, numeric_vars, drop = FALSE]
cor_matrix <- cor(numeric_predictors, use = "complete.obs")
# Find highly correlated pairs
highly_correlated <- which(abs(cor_matrix) > threshold & upper.tri(cor_matrix), arr.ind = TRUE)
if (nrow(highly_correlated) > 0) {
# Get correlated pairs
correlated_pairs <- data.frame(
Var1 = numeric_vars[highly_correlated[, 1]],
Var2 = numeric_vars[highly_correlated[, 2]],
Correlation = cor_matrix[highly_correlated]
)
message("Highly correlated numeric predictor pairs (threshold = ", threshold, "):")
print(correlated_pairs)
# Identify variables to remove (keeping one from each pair)
for (i in 1:nrow(correlated_pairs)) {
pair <- as.character(correlated_pairs[i, 1:2])
if (!(pair[1] %in% vars_to_remove) && !(pair[2] %in% vars_to_remove)) {
vars_to_remove <- c(vars_to_remove, pair[2])
}
}
} else {
message("No numeric predictors are highly correlated (above threshold = ", threshold, ")")
}
} else if (length(numeric_vars) > 0) {
message("Only ", length(numeric_vars), " numeric predictor - cannot calculate correlations")
}
# 2. Handle categorical predictors -------------------------------------------
categorical_vars <- names(predictors)[!numeric_cols & sapply(predictors, function(x) is.factor(x) | is.character(x))]
if (length(categorical_vars) > 0) {
message("\nChecking categorical predictors for outcome correlation...")
# Get the response variable
y <- model_data[[response_name]]
for (cat_var in categorical_vars) {
x <- predictors[[cat_var]]
# Calculate mean outcome by category (for numeric response)
if (is.numeric(y)) {
means <- tapply(y, x, mean, na.rm = TRUE)
if (length(means) > 1) {
# Calculate pairwise absolute differences in means
mean_diff <- as.matrix(dist(means))
# Normalize by overall range of y
normalized_diff <- mean_diff / diff(range(y, na.rm = TRUE))
# Find categories with very similar means
similar_cats <- which(normalized_diff < (1 - cat_threshold) & upper.tri(normalized_diff), arr.ind = TRUE)
if (nrow(similar_cats) > 0) {
message("Categorical variable '", cat_var, "' has categories with similar outcome means:")
pairs <- data.frame(
Cat1 = levels(x)[similar_cats[, 1]],
Cat2 = levels(x)[similar_cats[, 2]],
MeanDiff = mean_diff[similar_cats],
NormalizedDiff = normalized_diff[similar_cats]
)
print(pairs)
# Consider removing this categorical variable if many similar categories
if (mean(normalized_diff) < (1 - cat_threshold)) {
message("> Considering removing '", cat_var, "' (many similar categories)")
vars_to_remove <- c(vars_to_remove, cat_var)
}
}
}
}
# For binary response, check proportion differences
if (is.factor(y) && nlevels(y) == 2) {
prop_table <- prop.table(table(x, y), 1)
if (any(apply(prop_table, 1, function(p) max(p) > cat_threshold))) {
message("Categorical variable '", cat_var, "' has categories with similar outcome proportions")
print(prop_table)
# Consider removing if any category predicts outcome too well
vars_to_remove <- c(vars_to_remove, cat_var)
}
}
}
}
# 3. Process removals -------------------------------------------------------
if (length(vars_to_remove) == 0) {
message("\nNo variables need to be removed based on correlation thresholds")
return(model)
}
message("\nRemoving these variables to reduce multicollinearity/similarity:")
message(paste(vars_to_remove, collapse = ", "))
# Create new formula without the problematic variables
remaining_vars <- setdiff(names(predictors), vars_to_remove)
new_formula <- reformulate(remaining_vars, response = response_name)
# Refit the model
new_model <- update(model, formula. = new_formula)
return(new_model)
}
model <- remove_highly_correlated(model) # remove colinear variables from data
#Perform Multivariable Linear Regression
summary(model)
#perform stepwise regression
library(MASS)
model = stepAIC(model, direction = "both", trace = FALSE) # Stepwise regression model with shannon measure
model_summary <- summary(model)
summary(model)
ps <- readRDS("continuous_data.rds") # read in ps file
#Rarefy Data
set.seed(13)
ps <- rarefy_even_depth(ps, 1e+05)
a_diversity <- estimate_richness(ps, measures = c("Shannon", "Chao1")) # calculate alpha diversity of each sample
sample_data <- ps@sam_data #extract sample data
sample_data$sample <- rownames(sample_data) #create column with sample
a_diversity$sample <- rownames(sample_data) #create same column in diversity object to be able to merge by
sample_data <- data.frame(sample_data) #convert sample data to data frame for merging
a_diversity <- merge(sample_data, a_diversity, by = c("sample")) #merge the data together
a_diversity <- mutate_if(a_diversity, is.character, as.factor) #change all character columns to factor
View(a_diversity)
a_diversity <- a_diversity |>
select(Inthelasttwoweekschildhadfever, InthelasttwoweekschildhadDiahearria, wheezilingorwhistlinginthelast1year, Age, Weight, Everhadvaccinated,
Ifseparetedwhatmaterialsyourkitchenmadefrom, Whatmaterialyourhousefloormadefrom, Siblings.Younger.than.12, Pet, Wood,
Doyoueatraworundercookedvegitables, Doyouuseschoollatrine, Ifwithsoaphowoftenyouuseit_A, Howoftendoyoubathinriver, Chao1)
a_diversity <- a_diversity |>
dplyr::select(Inthelasttwoweekschildhadfever, InthelasttwoweekschildhadDiahearria, wheezilingorwhistlinginthelast1year, Age, Weight, Everhadvaccinated,
Ifseparetedwhatmaterialsyourkitchenmadefrom, Whatmaterialyourhousefloormadefrom, Siblings.Younger.than.12, Pet, Wood,
Doyoueatraworundercookedvegitables, Doyouuseschoollatrine, Ifwithsoaphowoftenyouuseit_A, Howoftendoyoubathinriver, Chao1)
a_diversity <- a_diversity |>
dplyr::select(Inthelasttwoweekschildhadfever, InthelasttwoweekschildhadDiahearria, wheezilingorwhistlinginthelast1year, Age, weight, Everhadvaccinated,
Ifseparetedwhatmaterialsyourkitchenmadefrom, Whatmaterialyourhousefloormadefrom, Siblings.Younger.than.12, Pet, Wood,
Doyoueatraworundercookedvegitables, Doyouuseschoollatrine, Ifwithsoaphowoftenyouuseit_A, Howoftendoyoubathinriver, Chao1)
View(a_diversity)
model <- lm(Chao1 ~ . , data = a_diversity)
summary(model)
ps <- readRDS("continuous_data.rds") # read in ps file
#Rarefy Data
set.seed(13)
ps <- rarefy_even_depth(ps, 1e+05)
a_diversity <- estimate_richness(ps, measures = c("Shannon", "Chao1")) # calculate alpha diversity of each sample
sample_data <- ps@sam_data #extract sample data
sample_data$sample <- rownames(sample_data) #create column with sample
a_diversity$sample <- rownames(sample_data) #create same column in diversity object to be able to merge by
sample_data <- data.frame(sample_data) #convert sample data to data frame for merging
a_diversity <- merge(sample_data, a_diversity, by = c("sample")) #merge the data together
a_diversity <- mutate_if(a_diversity, is.character, as.factor) #change all character columns to factor
View(a_diversity)
a_diversity <- a_diversity |>
dplyr::select(Inthelasttwoweekschildhadfever, InthelasttwoweekschildhadDiahearria, Howmanytimesinthelastyearthechildhadwheeziling, Age, weight, Everhadvaccinated,
Ifseparetedwhatmaterialsyourkitchenmadefrom, Whatmaterialyourhousefloormadefrom, Siblings.Younger.than.12, Pet, Wood,
Doyoueatraworundercookedvegitables, Doyouuseschoollatrine, Ifwithsoaphowoftenyouuseit_A, Howoftendoyoubathinriver, Chao1)
model <- lm(Chao1 ~ . , data = a_diversity)
summary(model)
library(MASS)
step_model = stepAIC(model, direction = "both", trace = FALSE) # Stepwise regression model
summary(step_model)
ps <- readRDS("continuous_data.rds") # read in ps file
#Rarefy Data
set.seed(13)
ps <- rarefy_even_depth(ps, 1e+05)
a_diversity <- estimate_richness(ps, measures = c("Shannon", "Chao1")) # calculate alpha diversity of each sample
sample_data <- ps@sam_data #extract sample data
sample_data$sample <- rownames(sample_data) #create column with sample
a_diversity$sample <- rownames(sample_data) #create same column in diversity object to be able to merge by
sample_data <- data.frame(sample_data) #convert sample data to data frame for merging
a_diversity <- merge(sample_data, a_diversity, by = c("sample")) #merge the data together
a_diversity <- a_diversity |> # remove unnecessary columns for the model
dplyr::select(-sample, -se.chao1)
a_diversity <- mutate_if(a_diversity, is.character, as.factor) #change all character columns to factor
a_diversity <- a_diversity %>%
dplyr::select_if(~ !(is.factor(.) & nlevels(.) == 1)) # remove all columns where factor only has one level
a_diversity <- a_diversity |>
mutate(Chao_plus = Chao1/mean(a_diversity$Chao1)*100,
Shannon_plus = Shannon/mean(a_diversity$Shannon)*100,
Chao_Shannon = (Chao_plus + Shannon_plus)/2)
a_diversity <- a_diversity %>%
dplyr::select_if(~ length(unique(.)) > 1) # remove all columns where numeric has only one level
remove_na_columns <- function(df) {
# Check which columns have any NA values
na_columns <- sapply(df, function(x) any(is.na(x)))
# Keep only columns without NAs
df_clean <- df[, !na_columns, drop = FALSE]
return(df_clean)
}
a_diversity <- remove_na_columns(a_diversity)
a_diversity <- a_diversity |>
dplyr::select(-Chao1, -Chao_plus, -Shannon, -Shannon_plus)
a_diversity <- a_diversity[,c(1:16, 33:46, 54:78, 88:93, 116)]
model <- lm(Chao_Shannon ~ ., data = a_diversity, na.action = na.omit)
summary(model)
top10_rsquared <- function(model) {
# Check if the input is a linear model
if (!inherits(model, "lm")) {
stop("Input must be a linear model (lm) object")
}
# Get the model data and formula
model_data <- model.frame(model)
response_var <- as.character(formula(model)[[2]])
# Get all predictor variables
predictors <- setdiff(colnames(model_data), response_var)
# If there are 10 or fewer predictors, return them all
if (length(predictors) <= 10) {
message("Model has 10 or fewer predictors - returning all variables")
return(predictors)
}
# Calculate individual R-squared contributions
rsq_contributions <- sapply(predictors, function(var) {
# Create a formula with just this predictor
f <- as.formula(paste(response_var, "~", var))
# Fit a simple model
m <- lm(f, data = model_data)
# Return R-squared
summary(m)$r.squared
})
# Sort by R-squared in descending order
sorted_vars <- names(sort(rsq_contributions, decreasing = TRUE))
# Return the top 10
return(sorted_vars[1:10])
}
top10_rsquared(model)
best_vars <- top10_rsquared(model)
View(a_diversity)
